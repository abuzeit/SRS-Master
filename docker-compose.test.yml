# =============================================================================
# SRS Master — Single-Server Test Stack (Phase 1)
# =============================================================================
#
# Runs EVERYTHING on a single Proxmox host for testing and validation:
#
#   Master Stack:
#     - 3 Kafka brokers (KRaft)
#     - Topic initialization
#     - Central PostgreSQL historian
#     - Consumer (master aggregator)
#
#   Simulated Remote Sites (3 producers):
#     - Producer-1 (NODE_ID=1, PLANT01/AREA01) + outbox-pg-1
#     - Producer-2 (NODE_ID=2, PLANT01/AREA02) + outbox-pg-2
#     - Producer-3 (NODE_ID=3, PLANT02/AREA01) + outbox-pg-3
#
# Usage:
#   docker compose -f docker-compose.test.yml up -d
#   docker compose -f docker-compose.test.yml logs -f
#   docker compose -f docker-compose.test.yml down -v
#
# =============================================================================

services:

  # ===========================================================================
  # MASTER STATION — Kafka Cluster
  # ===========================================================================

  kafka-1:
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka-1
    container_name: srs-kafka-1
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093,2@kafka-2:29093,3@kafka-3:29093"
      CLUSTER_ID: "SRS-SCADA-KAFKA-CLUSTER-01"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093,INTERNAL://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-1:9092,INTERNAL://kafka-1:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 200
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_MESSAGE_MAX_BYTES: 1048576
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    volumes:
      - kafka-1-data:/var/lib/kafka/data
    networks:
      - scada-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 | grep -q 'ApiVersion'" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  kafka-2:
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka-2
    container_name: srs-kafka-2
    ports:
      - "9094:9092"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093,2@kafka-2:29093,3@kafka-3:29093"
      CLUSTER_ID: "SRS-SCADA-KAFKA-CLUSTER-01"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093,INTERNAL://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-2:9092,INTERNAL://kafka-2:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 200
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_MESSAGE_MAX_BYTES: 1048576
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    volumes:
      - kafka-2-data:/var/lib/kafka/data
    networks:
      - scada-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 | grep -q 'ApiVersion'" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  kafka-3:
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka-3
    container_name: srs-kafka-3
    ports:
      - "9095:9092"
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093,2@kafka-2:29093,3@kafka-3:29093"
      CLUSTER_ID: "SRS-SCADA-KAFKA-CLUSTER-01"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093,INTERNAL://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-3:9092,INTERNAL://kafka-3:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 200
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_MESSAGE_MAX_BYTES: 1048576
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    volumes:
      - kafka-3-data:/var/lib/kafka/data
    networks:
      - scada-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 | grep -q 'ApiVersion'" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  kafka-init:
    image: confluentinc/cp-kafka:7.6.0
    container_name: srs-kafka-init
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    volumes:
      - ./kafka/scripts:/scripts:ro
    entrypoint: [ "/bin/bash", "-c" ]
    command:
      - |
        echo "Waiting for Kafka cluster to stabilize..."
        sleep 10
        echo "Creating topics..."
        KAFKA_BIN="" /scripts/create-topics.sh kafka-1:9092
        echo "Topic initialization complete."
    networks:
      - scada-network
    restart: "no"

  # ===========================================================================
  # MASTER STATION — Central Historian Database
  # ===========================================================================

  postgres:
    image: postgres:16-alpine
    hostname: postgres
    container_name: srs-postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: scada_historian
      POSTGRES_USER: scada
      POSTGRES_PASSWORD: ${DB_PASSWORD:-scada-secret-change-me}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
    networks:
      - scada-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U scada -d scada_historian" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    command:
      - "postgres"
      - "-c"
      - "shared_buffers=256MB"
      - "-c"
      - "max_connections=200"
      - "-c"
      - "work_mem=16MB"
      - "-c"
      - "maintenance_work_mem=128MB"
      - "-c"
      - "effective_cache_size=512MB"
      - "-c"
      - "checkpoint_completion_target=0.9"
      - "-c"
      - "wal_buffers=16MB"
      - "-c"
      - "random_page_cost=1.1"

  # ===========================================================================
  # MASTER STATION — Consumer (Master Aggregator)
  # ===========================================================================

  consumer:
    build:
      context: .
      dockerfile: packages/consumer/Dockerfile
    container_name: srs-consumer
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KAFKA_CLIENT_ID: master-aggregator
      KAFKA_CONSUMER_GROUP_ID: master-aggregator
      DATABASE_URL: postgresql://scada:${DB_PASSWORD:-scada-secret-change-me}@postgres:5432/scada_historian?schema=public
      LOG_LEVEL: info
    networks:
      - scada-network
    restart: unless-stopped

  # ===========================================================================
  # REMOTE SITE 1 — Producer Node 1 (PLANT01 / AREA01)
  # ===========================================================================

  outbox-pg-1:
    image: postgres:16-alpine
    hostname: outbox-pg-1
    container_name: srs-outbox-pg-1
    ports:
      - "5433:5432"
    environment:
      POSTGRES_DB: scada_outbox
      POSTGRES_USER: producer
      POSTGRES_PASSWORD: ${PRODUCER_DB_PASSWORD:-producer-db-secret}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    volumes:
      - outbox-pg-1-data:/var/lib/postgresql/data
    networks:
      - scada-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U producer -d scada_outbox" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  producer-1:
    build:
      context: .
      dockerfile: packages/producer/Dockerfile
    container_name: srs-producer-1
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      outbox-pg-1:
        condition: service_healthy
    environment:
      NODE_ID: 1
      PLANT_ID: PLANT01
      AREA_ID: AREA01
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KAFKA_CLIENT_ID: scada-producer-01
      PRODUCER_INTERVAL_MS: 1000
      PRODUCER_DATABASE_URL: postgresql://producer:${PRODUCER_DB_PASSWORD:-producer-db-secret}@outbox-pg-1:5432/scada_outbox?schema=public
      OUTBOX_BATCH_SIZE: 50
      OUTBOX_POLL_INTERVAL_MS: 500
      OUTBOX_MAX_RETRIES: 10
      OUTBOX_LOCK_TIMEOUT_SECONDS: 120
      OUTBOX_RECOVERY_INTERVAL_MS: 30000
      LOG_LEVEL: info
    networks:
      - scada-network
    restart: unless-stopped

  # ===========================================================================
  # REMOTE SITE 2 — Producer Node 2 (PLANT01 / AREA02)
  # ===========================================================================

  outbox-pg-2:
    image: postgres:16-alpine
    hostname: outbox-pg-2
    container_name: srs-outbox-pg-2
    ports:
      - "5434:5432"
    environment:
      POSTGRES_DB: scada_outbox
      POSTGRES_USER: producer
      POSTGRES_PASSWORD: ${PRODUCER_DB_PASSWORD:-producer-db-secret}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    volumes:
      - outbox-pg-2-data:/var/lib/postgresql/data
    networks:
      - scada-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U producer -d scada_outbox" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  producer-2:
    build:
      context: .
      dockerfile: packages/producer/Dockerfile
    container_name: srs-producer-2
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      outbox-pg-2:
        condition: service_healthy
    environment:
      NODE_ID: 2
      PLANT_ID: PLANT01
      AREA_ID: AREA02
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KAFKA_CLIENT_ID: scada-producer-02
      PRODUCER_INTERVAL_MS: 1000
      PRODUCER_DATABASE_URL: postgresql://producer:${PRODUCER_DB_PASSWORD:-producer-db-secret}@outbox-pg-2:5432/scada_outbox?schema=public
      OUTBOX_BATCH_SIZE: 50
      OUTBOX_POLL_INTERVAL_MS: 500
      OUTBOX_MAX_RETRIES: 10
      OUTBOX_LOCK_TIMEOUT_SECONDS: 120
      OUTBOX_RECOVERY_INTERVAL_MS: 30000
      LOG_LEVEL: info
    networks:
      - scada-network
    restart: unless-stopped

  # ===========================================================================
  # REMOTE SITE 3 — Producer Node 3 (PLANT02 / AREA01)
  # ===========================================================================

  outbox-pg-3:
    image: postgres:16-alpine
    hostname: outbox-pg-3
    container_name: srs-outbox-pg-3
    ports:
      - "5435:5432"
    environment:
      POSTGRES_DB: scada_outbox
      POSTGRES_USER: producer
      POSTGRES_PASSWORD: ${PRODUCER_DB_PASSWORD:-producer-db-secret}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    volumes:
      - outbox-pg-3-data:/var/lib/postgresql/data
    networks:
      - scada-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U producer -d scada_outbox" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  producer-3:
    build:
      context: .
      dockerfile: packages/producer/Dockerfile
    container_name: srs-producer-3
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      outbox-pg-3:
        condition: service_healthy
    environment:
      NODE_ID: 3
      PLANT_ID: PLANT02
      AREA_ID: AREA01
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KAFKA_CLIENT_ID: scada-producer-03
      PRODUCER_INTERVAL_MS: 1000
      PRODUCER_DATABASE_URL: postgresql://producer:${PRODUCER_DB_PASSWORD:-producer-db-secret}@outbox-pg-3:5432/scada_outbox?schema=public
      OUTBOX_BATCH_SIZE: 50
      OUTBOX_POLL_INTERVAL_MS: 500
      OUTBOX_MAX_RETRIES: 10
      OUTBOX_LOCK_TIMEOUT_SECONDS: 120
      OUTBOX_RECOVERY_INTERVAL_MS: 30000
      LOG_LEVEL: info
    networks:
      - scada-network
    restart: unless-stopped

# =============================================================================
# Volumes
# =============================================================================
volumes:
  kafka-1-data:
    name: srs-test-kafka-1-data
  kafka-2-data:
    name: srs-test-kafka-2-data
  kafka-3-data:
    name: srs-test-kafka-3-data
  postgres-data:
    name: srs-test-postgres-data
  outbox-pg-1-data:
    name: srs-test-outbox-pg-1-data
  outbox-pg-2-data:
    name: srs-test-outbox-pg-2-data
  outbox-pg-3-data:
    name: srs-test-outbox-pg-3-data

# =============================================================================
# Network
# =============================================================================
networks:
  scada-network:
    name: srs-scada-test-network
    driver: bridge
