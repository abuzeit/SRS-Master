# =============================================================================
# SRS Master — Master Station Stack (Production Phase 2)
# =============================================================================
#
# Deployed on the 2 Master Proxmox servers.
# Contains the central infrastructure that remote sites connect to:
#
#   - 3 Kafka brokers (KRaft mode) with EXTERNAL listeners
#   - Central PostgreSQL historian
#   - Consumer (master aggregator)
#   - Topic initialization (one-shot)
#
# Remote sites connect via the EXTERNAL listener on port 9092.
# Set MASTER_HOST_IP in .env.master to the server's LAN/WAN IP.
#
# Usage:
#   cp .env.master .env
#   docker compose -f docker-compose.master.yml up -d
#
# For HA (2 Proxmox servers):
#   Server 1: kafka-1, kafka-2, consumer, postgres
#   Server 2: kafka-3, consumer-2 (add in override file)
#   Set KAFKA_CONTROLLER_QUORUM_VOTERS to reference both server IPs.
#
# =============================================================================

services:

  # ===========================================================================
  # Kafka Broker 1 — With EXTERNAL listener for remote sites
  # ===========================================================================
  kafka-1:
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka-1
    container_name: srs-kafka-1
    ports:
      - "9092:9092" # External access for remote sites
      - "9093:9093" # Internal broker communication
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093,2@kafka-2:29093,3@kafka-3:29093"
      CLUSTER_ID: "SRS-SCADA-KAFKA-CLUSTER-01"

      # Listener Configuration:
      #   EXTERNAL  — Remote sites connect via host IP (TLS/SASL in production)
      #   INTERNAL  — Broker-to-broker communication
      #   CONTROLLER — KRaft consensus
      KAFKA_LISTENERS: "EXTERNAL://0.0.0.0:9092,INTERNAL://0.0.0.0:9093,CONTROLLER://0.0.0.0:29093"
      KAFKA_ADVERTISED_LISTENERS: "EXTERNAL://${MASTER_HOST_IP:-localhost}:9092,INTERNAL://kafka-1:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"

      # Replication
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 200

      # Performance tuning
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_MESSAGE_MAX_BYTES: 1048576
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
      # # TLS/SASL — Uncomment for production
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "EXTERNAL:SASL_SSL,INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      # KAFKA_SASL_ENABLED_MECHANISMS: "SCRAM-SHA-512"
      # KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: "SCRAM-SHA-512"
      # KAFKA_SSL_KEYSTORE_FILENAME: "kafka-1.keystore.jks"
      # KAFKA_SSL_KEYSTORE_PASSWORD: "${KAFKA_KEYSTORE_PASSWORD}"
      # KAFKA_SSL_KEY_PASSWORD: "${KAFKA_KEY_PASSWORD}"
      # KAFKA_SSL_TRUSTSTORE_FILENAME: "kafka.truststore.jks"
      # KAFKA_SSL_TRUSTSTORE_PASSWORD: "${KAFKA_TRUSTSTORE_PASSWORD}"
    volumes:
      - kafka-1-data:/var/lib/kafka/data
      # - ./kafka/certs:/etc/kafka/secrets:ro  # Uncomment for TLS
    networks:
      - scada-master-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 | grep -q 'ApiVersion'" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ===========================================================================
  # Kafka Broker 2
  # ===========================================================================
  kafka-2:
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka-2
    container_name: srs-kafka-2
    ports:
      - "9094:9092"
      - "9096:9093"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093,2@kafka-2:29093,3@kafka-3:29093"
      CLUSTER_ID: "SRS-SCADA-KAFKA-CLUSTER-01"
      KAFKA_LISTENERS: "EXTERNAL://0.0.0.0:9092,INTERNAL://0.0.0.0:9093,CONTROLLER://0.0.0.0:29093"
      KAFKA_ADVERTISED_LISTENERS: "EXTERNAL://${MASTER_HOST_IP:-localhost}:9094,INTERNAL://kafka-2:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 200
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_MESSAGE_MAX_BYTES: 1048576
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    volumes:
      - kafka-2-data:/var/lib/kafka/data
    networks:
      - scada-master-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 | grep -q 'ApiVersion'" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ===========================================================================
  # Kafka Broker 3
  # ===========================================================================
  kafka-3:
    image: confluentinc/cp-kafka:7.6.0
    hostname: kafka-3
    container_name: srs-kafka-3
    ports:
      - "9095:9092"
      - "9097:9093"
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093,2@kafka-2:29093,3@kafka-3:29093"
      CLUSTER_ID: "SRS-SCADA-KAFKA-CLUSTER-01"
      KAFKA_LISTENERS: "EXTERNAL://0.0.0.0:9092,INTERNAL://0.0.0.0:9093,CONTROLLER://0.0.0.0:29093"
      KAFKA_ADVERTISED_LISTENERS: "EXTERNAL://${MASTER_HOST_IP:-localhost}:9095,INTERNAL://kafka-3:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_NUM_PARTITIONS: 200
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_MESSAGE_MAX_BYTES: 1048576
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
    volumes:
      - kafka-3-data:/var/lib/kafka/data
    networks:
      - scada-master-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 | grep -q 'ApiVersion'" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ===========================================================================
  # Kafka Topic Initialization
  # ===========================================================================
  kafka-init:
    image: confluentinc/cp-kafka:7.6.0
    container_name: srs-kafka-init
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    volumes:
      - ./kafka/scripts:/scripts:ro
    entrypoint: [ "/bin/bash", "-c" ]
    command:
      - |
        echo "Waiting for Kafka cluster to stabilize..."
        sleep 10
        echo "Creating topics..."
        KAFKA_BIN="" /scripts/create-topics.sh kafka-1:9092
        echo "Topic initialization complete."
    networks:
      - scada-master-network
    restart: "no"

  # ===========================================================================
  # Central Historian Database
  # ===========================================================================
  postgres:
    image: postgres:16-alpine
    hostname: postgres
    container_name: srs-postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: scada_historian
      POSTGRES_USER: scada
      POSTGRES_PASSWORD: ${DB_PASSWORD:-scada-secret-change-me}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
    networks:
      - scada-master-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U scada -d scada_historian" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    command:
      - "postgres"
      - "-c"
      - "shared_buffers=256MB"
      - "-c"
      - "max_connections=200"
      - "-c"
      - "work_mem=16MB"
      - "-c"
      - "maintenance_work_mem=128MB"
      - "-c"
      - "effective_cache_size=512MB"
      - "-c"
      - "checkpoint_completion_target=0.9"
      - "-c"
      - "wal_buffers=16MB"
      - "-c"
      - "random_page_cost=1.1"

  # ===========================================================================
  # Consumer — Master Aggregator
  # ===========================================================================
  consumer:
    build:
      context: .
      dockerfile: packages/consumer/Dockerfile
    container_name: srs-consumer
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      KAFKA_BROKERS: kafka-1:9092,kafka-2:9092,kafka-3:9092
      KAFKA_CLIENT_ID: master-aggregator
      KAFKA_CONSUMER_GROUP_ID: master-aggregator
      DATABASE_URL: postgresql://scada:${DB_PASSWORD:-scada-secret-change-me}@postgres:5432/scada_historian?schema=public
      LOG_LEVEL: info
      # # TLS/SASL — Uncomment for production
      # KAFKA_SASL_USERNAME: consumer-user
      # KAFKA_SASL_PASSWORD: ${CONSUMER_PASSWORD}
      # KAFKA_SSL_CA_PATH: /certs/ca-cert.pem
      # volumes:
      #   - ./kafka/certs:/certs:ro  # Uncomment for TLS
    networks:
      - scada-master-network
    restart: unless-stopped

# =============================================================================
# Volumes
# =============================================================================
volumes:
  kafka-1-data:
    name: srs-master-kafka-1-data
  kafka-2-data:
    name: srs-master-kafka-2-data
  kafka-3-data:
    name: srs-master-kafka-3-data
  postgres-data:
    name: srs-master-postgres-data

# =============================================================================
# Network
# =============================================================================
networks:
  scada-master-network:
    name: srs-scada-master-network
    driver: bridge
