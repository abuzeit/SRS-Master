# =============================================================================
# SRS Master — Environment Configuration Template
# =============================================================================
# SECURITY: Copy this file to .env and fill in real values.
#           NEVER commit .env to version control.
# =============================================================================

# -----------------------------------------------------------------------------
# Node Identity — Each remote server gets a unique NODE_ID (1–100)
# -----------------------------------------------------------------------------
NODE_ID=1
PLANT_ID=PLANT01
AREA_ID=AREA01

# -----------------------------------------------------------------------------
# Kafka Broker Addresses
# Format: host1:port1,host2:port2,host3:port3
# -----------------------------------------------------------------------------
KAFKA_BROKERS=kafka-1:9093,kafka-2:9093,kafka-3:9093
KAFKA_CLIENT_ID=scada-producer-01

# -----------------------------------------------------------------------------
# Kafka Security — SASL/SCRAM-SHA-512
# -----------------------------------------------------------------------------
KAFKA_SASL_USERNAME=producer-user
KAFKA_SASL_PASSWORD=CHANGE_ME_producer_password

# -----------------------------------------------------------------------------
# Kafka Security — TLS
# Paths to PEM-encoded certificate files
# -----------------------------------------------------------------------------
KAFKA_SSL_CA_PATH=/certs/ca-cert.pem
KAFKA_SSL_CERT_PATH=/certs/client-cert.pem
KAFKA_SSL_KEY_PATH=/certs/client-key.pem

# -----------------------------------------------------------------------------
# Kafka Consumer Group (Master Station only)
# -----------------------------------------------------------------------------
KAFKA_CONSUMER_GROUP_ID=master-aggregator

# -----------------------------------------------------------------------------
# PostgreSQL — Central Historian Database (Prisma v6)
# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE?schema=public
# -----------------------------------------------------------------------------
DATABASE_URL=postgresql://scada:CHANGE_ME_db_password@postgres:5432/scada_historian?schema=public

# -----------------------------------------------------------------------------
# Producer Tuning
# -----------------------------------------------------------------------------
PRODUCER_INTERVAL_MS=1000
PRODUCER_BATCH_SIZE=10

# -----------------------------------------------------------------------------
# Producer Local Database — Outbox Pattern (Prisma v6)
# Each SCADA node has its OWN local PostgreSQL for the outbox.
# Format: postgresql://USER:PASSWORD@HOST:PORT/DATABASE?schema=public
# -----------------------------------------------------------------------------
PRODUCER_DATABASE_URL=postgresql://producer:CHANGE_ME_producer_db_password@producer-postgres:5432/scada_outbox?schema=public
PRODUCER_DB_PASSWORD=CHANGE_ME_producer_db_password

# -----------------------------------------------------------------------------
# Outbox Dispatcher Tuning
# These control how the outbox dispatcher publishes events to Kafka.
# -----------------------------------------------------------------------------
OUTBOX_BATCH_SIZE=50                   # Events fetched per dispatch cycle
OUTBOX_POLL_INTERVAL_MS=500            # Milliseconds between dispatch cycles
OUTBOX_MAX_RETRIES=10                  # Max retries before marking FAILED (poison)
OUTBOX_LOCK_TIMEOUT_SECONDS=120        # Stale lock detection threshold
OUTBOX_RECOVERY_INTERVAL_MS=30000      # How often to check for stale locks
METRICS_LOG_INTERVAL=60                # Log outbox metrics every N cycles

# -----------------------------------------------------------------------------
# Outbox Pruning / Maintenance
# These control how long data is kept locally before being deleted.
# -----------------------------------------------------------------------------
STORAGE_RETENTION_DAYS=30              # Keep SENT events & local telemetry for N days
PRUNE_INTERVAL_MS=3600000              # Run pruning task every N ms (default: 1 hour)


# -----------------------------------------------------------------------------
# Consumer Tuning
# -----------------------------------------------------------------------------
CONSUMER_BATCH_SIZE=100
CONSUMER_SESSION_TIMEOUT_MS=30000
CONSUMER_HEARTBEAT_INTERVAL_MS=3000

# -----------------------------------------------------------------------------
# Docker Compose Passwords (used in docker-compose.yml defaults)
# Generate strong values for production:
#   openssl rand -base64 32
# -----------------------------------------------------------------------------
DB_PASSWORD=CHANGE_ME_historian_db_password
PRODUCER_DB_PASSWORD=CHANGE_ME_producer_db_password

# -----------------------------------------------------------------------------
# Logging
# Valid levels: debug, info, warn, error
# -----------------------------------------------------------------------------
LOG_LEVEL=info

